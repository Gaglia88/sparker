{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "champion-strain",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparker\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-manor",
   "metadata": {},
   "source": [
    "# Generalized supervised meta-blocking\n",
    "Generalized Supervised Meta-blocking employs the probability provided by a probabilistic classifier to score the edges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mounted-testimony",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "First, load a clean dataset with the groundtruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "german-reply",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles1 = sparker.JSONWrapper.load_profiles('../datasets/clean/DblpAcm/dataset1.json', \n",
    "                                              real_id_field = \"realProfileID\",\n",
    "                                              source_id=1)\n",
    "separator_id = profiles1.map(lambda profile: profile.profile_id).max()\n",
    "separator_ids = [separator_id]\n",
    "\n",
    "profiles2 = sparker.JSONWrapper.load_profiles('../datasets/clean/DblpAcm/dataset2.json', \n",
    "                                              start_id_from = separator_id+1, \n",
    "                                              real_id_field = \"realProfileID\",\n",
    "                                              source_id=2)\n",
    "max_profile_id = profiles2.map(lambda profile: profile.profile_id).max()\n",
    "profiles = profiles1.union(profiles2)\n",
    "\n",
    "gt = sparker.JSONWrapper.load_groundtruth('../datasets/clean/DblpAcm/groundtruth.json', 'id1', 'id2')\n",
    "new_gt = sparker.Converters.convert_groundtruth(gt, profiles1, profiles2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-allergy",
   "metadata": {},
   "source": [
    "## Blocking \n",
    "\n",
    "Performs the blocking by using standard token blocking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "funded-manual",
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = sparker.Blocking.create_blocks(profiles, separator_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominant-christianity",
   "metadata": {},
   "source": [
    "## Block cleaning\n",
    "Applying some block cleaning techniques to remove some superfluous comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "little-yorkshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perfoms the purging\n",
    "blocks_purged = sparker.BlockPurging.block_purging(blocks, 1.025)\n",
    "# Performs the cleaning\n",
    "(profile_blocks, profile_blocks_filtered, blocks_after_filtering) = sparker.BlockFiltering.\\\n",
    "                                                                            block_filtering_quick(blocks_purged, \n",
    "                                                                                                  0.8, \n",
    "                                                                                                  separator_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "democratic-mortality",
   "metadata": {},
   "source": [
    "## Features generation\n",
    "Generate the features set for each pair of entity profiles that co-occurs in at least one block (i.e. the edges of the meta-blocking graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hourly-drain",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = sparker.FeatureGenerator.generate_features(profiles, blocks_after_filtering, separator_ids, new_gt, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "chinese-saint",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---------+------------+------------+---------+---------+----------+----------+------------+------------+--------+\n",
      "| p1|  p2|    cfibf|       raccb|          js|numCompP1|numCompP2|        rs|      aejs|         nrs|         wjs|is_match|\n",
      "+---+----+---------+------------+------------+---------+---------+----------+----------+------------+------------+--------+\n",
      "|  0|2880|43.542595|0.0011947431|0.0036764706|      143|       86|0.01724138| 1.0872893| 0.006724811|2.8883503E-4|       0|\n",
      "|  0|2689|42.852882|0.0011947431|0.0036630037|      143|       84|0.01724138| 1.1100789| 0.011110576|8.1310613E-4|       0|\n",
      "|  0|4610|42.852882|0.0011947431|0.0031055901|      143|      151|0.01724138| 1.0214063| 0.013291508|0.0010024176|       0|\n",
      "|  0|3329| 39.37928|0.0011947431|0.0028735632|      143|      151|0.01724138| 0.7247032| 0.004989114|2.2629971E-4|       0|\n",
      "|  0|2883| 45.18775|0.0011947431|0.0034722222|      143|      112|0.01724138| 1.1792971|   0.0170716| 0.001097521|       0|\n",
      "|  0|4870| 44.31363|0.0011947431|0.0035971224|      143|       97|0.01724138| 1.1763238|  0.01313642| 8.838394E-4|       0|\n",
      "|  0|4423|42.228962|0.0011947431|0.0032467532|      143|      134|0.01724138|  0.895778| 0.010370908| 7.626709E-4|       0|\n",
      "|  0|3911|39.005108|0.0011947431|0.0034843206|      143|      103|0.01724138|0.74891895|0.0038116646| 1.870671E-4|       0|\n",
      "|  0|3406|42.228962|0.0011947431|0.0040650405|      143|       74|0.01724138|  1.102616| 0.004990128|2.1838513E-4|       0|\n",
      "|  0|3983| 41.13539|0.0011947431|0.0037037036|      143|       78|0.01724138|0.86617297| 0.008453612|6.0498924E-4|       0|\n",
      "+---+----+---------+------------+------------+---------+---------+----------+----------+------------+------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-government",
   "metadata": {},
   "source": [
    "## Scoring the edges\n",
    "By using a probabilistic classifier (logistic regression) we assign to each pair (edge of the meta-blocking graph) the probability of being a match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cooked-spotlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.types import FloatType, BooleanType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annual-savings",
   "metadata": {},
   "source": [
    "### Generation of the feature vector for the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "coated-designation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features to employ\n",
    "features_set = [\"cfibf\", \"raccb\", \"js\", \"numCompP1\", \"numCompP2\", \"rs\", \"aejs\", \"nrs\", \"wjs\"]\n",
    "\n",
    "va = VectorAssembler(inputCols=features_set, outputCol=\"features\")\n",
    "\n",
    "df = va.transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informational-sentence",
   "metadata": {},
   "source": [
    "### Split the data in train/test\n",
    "This will generate a balanced training set in which the number of positive/negative samples is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "selected-tracker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of samples per class (actually spark do not ensure this exact value during sampling)\n",
    "n_samples = 20\n",
    "\n",
    "# Sampling of matching pairs\n",
    "matches = df.where(\"is_match == 1\")\n",
    "m_n = n_samples/matches.count()\n",
    "m_train, m_test = matches.randomSplit([m_n, 1-m_n])\n",
    "\n",
    "# Sampling of non-matching pairs\n",
    "non_matches = df.where(\"is_match == 0\")\n",
    "nm_n = n_samples/non_matches.count()\n",
    "nm_train, nm_test = non_matches.randomSplit([nm_n, 1-nm_n])\n",
    "\n",
    "# Train/Test\n",
    "train = m_train.union(nm_train)\n",
    "test = m_test.union(nm_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-suffering",
   "metadata": {},
   "source": [
    "### Training the classifier and get the probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "miniature-stomach",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178234"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(featuresCol='features', \n",
    "                        labelCol='is_match', \n",
    "                        predictionCol='prediction', \n",
    "                        maxIter=1000, \n",
    "                        probabilityCol='probability'\n",
    "                       )\n",
    "# Training\n",
    "model = lr.fit(train)\n",
    "# Performs the predictions\n",
    "predictions = model.transform(test)\n",
    "\n",
    "# Get the results as the probability of each pair (edge) of being a match\n",
    "get_p_match = f.udf(lambda v: float(v[1]), FloatType())\n",
    "edges = predictions\\\n",
    "        .withColumn(\"p_match\", get_p_match(\"probability\"))\\\n",
    "        .select(\"p1\", \"p2\", \"p_match\", \"is_match\")\n",
    "\n",
    "edges.cache()\n",
    "edges.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-election",
   "metadata": {},
   "source": [
    "## Perform the pruning\n",
    "Perform the pruning and get the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "therapeutic-approach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall 0.9806654676258992\n",
      "Precision 0.5608125482129082\n",
      "F1 0.7135612628823818\n"
     ]
    }
   ],
   "source": [
    "pruned_edges = sparker.SupervisedMB.wep(edges)\n",
    "pc, pq, f1 = sparker.SupervisedMB.get_stats(pruned_edges, new_gt)\n",
    "print(\"Recall \"+str(pc))\n",
    "print(\"Precision \"+str(pq))\n",
    "print(\"F1 \"+str(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ambient-irrigation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall 0.9824640287769785\n",
      "Precision 0.519990480723465\n",
      "F1 0.6800497976968566\n"
     ]
    }
   ],
   "source": [
    "pruned_edges = sparker.SupervisedMB.blast(edges)\n",
    "pc, pq, f1 = sparker.SupervisedMB.get_stats(pruned_edges, new_gt)\n",
    "print(\"Recall \"+str(pc))\n",
    "print(\"Precision \"+str(pq))\n",
    "print(\"F1 \"+str(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "noble-shanghai",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall 0.9824640287769785\n",
      "Precision 0.512670107930549\n",
      "F1 0.6737588652482269\n"
     ]
    }
   ],
   "source": [
    "pruned_edges = sparker.SupervisedMB.rcnp(edges, profiles, blocks)\n",
    "pc, pq, f1 = sparker.SupervisedMB.get_stats(pruned_edges, new_gt)\n",
    "print(\"Recall \"+str(pc))\n",
    "print(\"Precision \"+str(pq))\n",
    "print(\"F1 \"+str(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "numerous-decimal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall 0.9824640287769785\n",
      "Precision 0.5124296435272045\n",
      "F1 0.6735511713933416\n"
     ]
    }
   ],
   "source": [
    "pruned_edges = sparker.SupervisedMB.cnp(edges, profiles, blocks)\n",
    "pc, pq, f1 = sparker.SupervisedMB.get_stats(pruned_edges, new_gt)\n",
    "print(\"Recall \"+str(pc))\n",
    "print(\"Precision \"+str(pq))\n",
    "print(\"F1 \"+str(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-namibia",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
